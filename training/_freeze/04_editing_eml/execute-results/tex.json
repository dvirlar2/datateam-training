{
  "hash": "f0084716c02affb943ddf6f1fe0952ff",
  "result": {
    "markdown": "---\ntitle: \"Editing EML\"\n# output-dir: docs \nfreeze: true\n---\n\n\n\nThis chapter is a practical tutorial for using R to read, edit, write, and validate EML documents. Much of the information here can also be found in the vignettes for the R packages used in this section (e.g. the <a href = 'https://github.com/ropensci/EML/blob/master/vignettes/creating-EML.qmd' target='_blank'>EML package</a>). \n\nMost of the functions you will see in this chapter will use the `arcticdatautils` and `EML` packages.\n\n:::{.callout-note}\nThis chapter will be longest of all the sections! This is a reminder to take frequent breaks when completing this section.\n:::\n\n## Edit an EML element\n\nThere are multiple ways to edit an EML element. \n\n### Edit EML with strings\n\nThe most basic way to edit an EML element would be to navigate to the element and replace it with something else. Easy!\n\nFor example, to change the title one could use the following command:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$title <- \"New Title\"\n```\n:::\n\n\nIf the element you are editing allows for multiple values, you can pass it a list of character strings. Since a dataset can have multiple titles, we can do this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$title <- list(\"New Title\", \"Second New Title\")\n```\n:::\n\n\n\nHowever, this isn't always the best method to edit the EML, particularly if the element has sub-elements.\n\n### Edit EML with the \"EML\" package\n\nTo edit a section where you are not 100% sure of the sub-elements, using the `eml$elementName()` helper functions from the EML package will pre-populate the options for you if you utilize the RStudio autocomplete functionality. The arguments in these functions show the available slots for any given EML element. For example, typing `doc$dataset$abstract <- eml$abstract()<TAB>` will show you that the `abstract` element can take either the `section` or `para` sub-elements. \n\n![](../../images/eml_function_autocomplete.png) \n\n![](images/eml_function_autocomplete.png) \n\n![](/images/eml_function_autocomplete.png) \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$abstract <- eml$abstract(para = \"A concise but thorough description of the who, what, where, when, why, and how of a dataset.\")\n```\n:::\n\n\nThis inserts the abstract with a `para` element in our dataset, which we know from the EML [schema](https://eml.ecoinformatics.org/schema/index.html) is valid.\n\nNote that the above is equivalent to the following generic construction:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$abstract <- list(para = \"A concise but thorough description of the who, what, where, when, why, and how of a dataset.\")\n```\n:::\n\n\nThe `eml()` family of functions provides the sub-elements as arguments, which is extremely helpful, but functionally all it is doing is creating a named list, which you can also do using the `list` function.\n\n\n### Edit EML with objects\n\nA final way to edit an EML element would be to build a new object to replace the old object. To begin, you might create an object using an `eml` helper function. Let's take keywords as an example. Sometimes keyword lists in a metadata record will come from different thesauruses, which you can then add in series (similar to the way we added multiple titles) to the element `keywordSet`.\n\nWe start by creating our first set of keywords and saving it to an object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkw_list_1 <- eml$keywordSet(keywordThesaurus = \"LTER controlled vocabulary\",\n                            keyword = list(\"bacteria\", \"carnivorous plants\", \"genetics\", \"thresholds\"))\n```\n:::\n\n\nWhich returns:\n\n```\n$keyword\n$keyword[[1]]\n[1] \"bacteria\"\n\n$keyword[[2]]\n[1] \"carnivorous plants\"\n\n$keyword[[3]]\n[1] \"genetics\"\n\n$keyword[[4]]\n[1] \"thresholds\"\n\n\n$keywordThesaurus\n[1] \"LTER controlled vocabulary\"\n```\n\nWe create the second keyword list similarly:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkw_list_2 <- eml$keywordSet(keywordThesaurus = \"LTER core area\", \n                            keyword =  list(\"populations\", \"inorganic nutrients\", \"disturbance\"))\n```\n:::\n\n\nFinally, we can insert our two keyword lists into our EML document just like we did with the title example above, but rather than passing character strings into `list()`, we will pass our two keyword set objects.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$keywordSet <- list(kw_list_1, kw_list_2)\n```\n:::\n\n\n:::{.callout-note}\nNote that you **must** use the function `list` here and not the `c()` function. The reasons for this are complex, and due to some technical subtlety in R - but the gist of the issue is that the `c()` function can behave in unexpected ways with nested lists, and frequently will collapse the nesting into a single level, resulting in invalid EML.\n:::\n\n\n\n\n## FAIR data practices\n\nThe result of these function calls won't show up on the webpage but they will add a `publisher` element to the `dataset` element and a `system` to all of the entities based on what the PID is. This will help make our metadata more FAIR (Findable, Accessible, Interoperable, Reusable). \n\nThese two functions come from the `arcticatautils` package, an R package we wrote to help with some very specific data processing tasks.\n\nAdd these function calls to all of your EML processing scripts.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  library(arcticdatautils)\n\n  doc <- eml_add_publisher(doc)\n  doc <- eml_add_entity_system(doc)\n```\n:::\n\n## Edit attributeLists\n\nAttributes are descriptions of variables, typically columns or column names in tabular data. Attributes are stored in an <a href = 'https://eml.ecoinformatics.org/images/eml-attribute.png' target='_blank'>attributeList</a>. When editing attributes in R, you need to create one to three objects:\n\n1. A data.frame of attributes\n2. A data.frame of custom units (if applicable)\n\nThe `attributeList` is an element within one of 4 different types of entity objects. An entity corresponds to a file, typically. Multiple entities (files) can exist within a dataset. The 4 different entity types are `dataTable` (most common for us), `spatialVector`, `spatialRaster`, and `otherEntity`\n\nPlease note that submitting attribute information through the website will store them in an `otherEntity` object by default. We prefer to store them in a `dataTable` object for tabular data or a `spatialVector` object for spatial data.\n\nTo edit or examine an existing attribute table already in an EML file, you can use the following commands, where `i` represents the index of the series element you are interested in. Note that if there is only one item in the series (ie there is only one `dataTable`), you should just call `doc$dataset$dataTable`, as in this case `doc$dataset$dataTable[[1]]` will return the first sub-element of the `dataTable` (the `entityName`)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# If they are stored in an otherEntity (submitted from the website by default)\nattributeList <- EML::get_attributes(doc$dataset$otherEntity[[i]]$attributeList)\n\n# Or if they are stored in a dataTable (usually created by a datateam member)\nattributeList <- EML::get_attributes(doc$dataset$dataTable[[i]]$attributeList)\n\n# Or if they are stored in a spatialVector (usually created by a datateam member)\nattributeList <- EML::get_attributes(doc$dataset$spatialVector[[i]]$attributeList)\n\nattributes <- attributeList$attributes\nprint(attributes)\n```\n:::\n\n\n### Edit attributes\n\nAttribute information should be stored in a `data.frame` with the following columns:\n\n* **attributeName**: The name of the attribute as listed in the csv. Required. e.g.: \"c_temp\"\n* **attributeLabel**: A descriptive label that can be used to display the name of an attribute. It is not constrained by system limitations on length or special characters. Optional. e.g.: \"Temperature (Celsius)\"\n* **attributeDefinition**: Longer description of the attribute, including the required context for interpreting the `attributeName`. Required. e.g.: \"The near shore water temperature in the upper inter-tidal zone, measured in degrees Celsius.\"\n* **measurementScale**: One of: nominal, ordinal, dateTime, ratio, interval. Required.\n    + *nominal*: unordered categories or text. e.g.: (Male, Female) or (Yukon River, Kuskokwim River)\n    + *ordinal*: ordered categories. e.g.: Low, Medium, High\n    + *dateTime*: date or time values from the Gregorian calendar. e.g.: 01-01-2001\n    + *ratio*: measurement scale with a meaningful zero point in nature. Ratios are proportional to the measured variable. e.g.: 0 Kelvin represents a complete absence of heat. 200 Kelvin is half as hot as 400 Kelvin. 1.2 meters per second is twice as fast as 0.6 meters per second.\n    + *interval*: values from a scale with equidistant points, where the zero point is arbitrary. This is usually reserved for degrees Celsius or Fahrenheit, or latitude and longitude coordinates, or any other human-constructed scale. e.g.: there is still heat at 0° Celsius; 12° Celsius is NOT half as hot as 24° Celsius.\n* **domain**: One of: `textDomain`, `enumeratedDomain`, `numericDomain`, `dateTime`. Required.\n    + *textDomain*: text that is free-form, or matches a pattern\n    + *enumeratedDomain*: text that belongs to a defined list of codes and definitions. e.g.: CASC = Cascade Lake, HEAR = Heart Lake\n    + *dateTimeDomain*: `dateTime` attributes\n    + *numericDomain*: attributes that are numbers (either `ratio` or `interval`)\n* **formatString**: Required for `dateTime`, NA otherwise. Format string for dates, e.g. \"DD/MM/YYYY\".\n* **definition**: Required for `textDomain`, NA otherwise. Definition for attributes that are a character string, matches attribute definition in most cases.\n* **unit**: Required for `numericDomain`, NA otherwise. Unit string. If the unit is not a standard unit, a warning will appear when you create the attribute list, saying that it has been forced into a custom unit. Use caution here to make sure the unit really needs to be a custom unit. A list of standard units can be found using: `standardUnits <- EML::get_unitList()` then running `View(standardUnits$units)`.\n* **numberType**: Required for `numericDomain`, NA otherwise. Options are `real`, `natural`, `whole`, and `integer`.\n    + *real*: positive and negative fractions and integers (...-1,-0.25,0,0.25,1...)\n    + *natural*: non-zero positive integers (1,2,3...)\n    + *whole*: positive integers and zero (0,1,2,3...)\n    + *integer*: positive and negative integers and zero (...-2,-1,0,1,2...)\n* **missingValueCode**: Code for missing values (e.g.: '-999', 'NA', 'NaN'). NA otherwise. Note that an NA missing value code should be a string, 'NA', and numbers should also be strings, '-999.'\n* **missingValueCodeExplanation**: Explanation for missing values, NA if no missing value code exists.\n\nYou can create attributes manually by typing them out in R following a workflow similar to the one below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nattributes <- data.frame(\n    \n    attributeName = c('Date', 'Location', 'Region','Sample_No', 'Sample_vol', \n                      'Salinity', 'Temperature', 'sampling_comments'),\n    \n    attributeDefinition = c('Date sample was taken on', \n                            'Location code representing location where sample was taken',\n                            'Region where sample was taken', 'Sample number', 'Sample volume', \n                            'Salinity of sample in PSU', 'Temperature of sample', \n                            'comments about sampling process'),\n    \n    measurementScale = c('dateTime', 'nominal','nominal', 'nominal', 'ratio', \n                         'ratio', 'interval', 'nominal'),\n    \n    domain = c('dateTimeDomain', 'enumeratedDomain','enumeratedDomain', \n               'textDomain', 'numericDomain', 'numericDomain', \n               'numericDomain', 'textDomain'),\n    \n    formatString = c('MM-DD-YYYY', NA,NA,NA,NA,NA,NA,NA),\n    \n    definition = c(NA,NA,NA,'Sample number', NA, NA, NA, \n                   'comments about sampling process'),\n    \n    unit = c(NA, NA, NA, NA,'milliliter', 'dimensionless', 'celsius', NA),\n    \n    numberType = c(NA, NA, NA,NA, 'real', 'real', 'real', NA),\n    \n    missingValueCode = c(NA, NA, NA,NA, NA, NA, NA, 'NA'),\n    \n    missingValueCodeExplanation = c(NA, NA, NA,NA, NA, NA, NA, \n                                    'no sampling comments'))\n```\n:::\n\n\nHowever, typing this out in R can be a major pain. Luckily, there's a Shiny app that you can use to build attribute information. You can use the app to build attributes from a data file loaded into R (recommended as the app will auto-fill some fields for you) to edit an existing attribute table, or to create attributes from scratch. Use the following commands to create or modify attributes (these commands will launch a Shiny app in your web browser):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#first download the CSV in your data package from Exercise #2\ndata_pid <- selectMember(dp, name = \"sysmeta@fileName\", value = \".csv\")\ndata <- read.csv(text=rawToChar(getObject(d1c_test@mn, data_pid)))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# From data (recommended)\nEML::shiny_attributes(data = data)\n\n# From an existing attribute table\nattributeList <- get_attributes(doc$dataset$dataTable[[i]]$attributeList)\nEML::shiny_attributes(data = NULL, attributes = attributeList$attributes)\n\n# From scratch\natts <- EML::shiny_attributes()\n```\n:::\n\n\nOnce you are done editing a table in the app, quit the app and the tables will be assigned to the `atts` variable as a list of data frames (one for attributes, factors, and units). Alternatively, each table can be to exported to a csv file by clicking the `Download` button.\n\nIf you downloaded the table, read the table back into your R session and assign it to a variable in your script (e.g. `attributes <- data.frame(...)`), or just use the variable that `shiny_attributes` returned.\n\nFor simple attribute corrections, `datamgmt::edit_attribute()` allows you to edit the slots of a single attribute within an attribute list. To use this function, pass an attribute through `datamgmt::edit_attribute()` and fill out the parameters you wish to edit/update. An example is provided below where we are changing `attributeName`, `domain`, and `measurementScale` in the first attribute of a dataset. After completing the edits, insert the new version of the attribute back into the EML document.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_attribute <- datamgmt::edit_attribute(doc$dataset$dataTable[[1]]$attributeList$attribute[[1]], \n                          attributeName = 'date_and_time', \n                          domain = 'dateTimeDomain', \n                          measurementScale = 'dateTime')\n\ndoc$dataset$dataTable[[1]]$attributeList$attribute[[1]] <- new_attribute\n```\n:::\n\n \n### Edit custom units\n\nEML has a set list of units that can be added to an EML file. These can be seen by using the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstandardUnits <- EML::get_unitList()\nView(standardUnits$units)\n```\n:::\n\n\nSearch the units list for your unit before attempting to create a custom unit. You can search part of the unit you can look up part of the unit ie `meters` in the table to see if there are any matches.\n\nIf you have units that are not in the standard EML unit list, you will need to build a custom unit list. A unit typically consists of the following fields:\n\n* **id**: The `unit id` (ids are camelCased)\n* **unitType**: The `unitType` (run `View(standardUnits$unitTypes)` to see standard `unitType`s)\n* **parentSI**: The `parentSI` unit (e.g. for kilometer `parentSI` = \"meter\")\n* **multiplierToSI**: Multiplier to the `parentSI` unit (e.g. for kilometer `multiplierToSI` = 1000)\n* **name**: Unit abbreviation (e.g. for kilometer `name` = \"km\")\n* **description**: Text defining the unit (e.g. for kilometer `description` = \"1000 meters\")\n\nTo manually generate the custom units list, create a dataframe with the fields mentioned above. An example is provided below that can be used as a template:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustom_units <- data.frame(   \n  id = c('siemensPerMeter', 'decibar'),\n  unitType = c('resistivity', 'pressure'),\n  parentSI = c('ohmMeter', 'pascal'),\n  multiplierToSI = c('1','10000'),\n  abbreviation = c('S/m','decibar'),\n  description = c('siemens per meter', 'decibar'))\n```\n:::\n\n\nUsing `EML::get_unit_id` for custom units will also generate valid EML unit ids. Custom units are then added to `additionalMetadata` using the following command:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunitlist <- set_unitList(custom_units, as_metadata = TRUE)\ndoc$additionalMetadata <-  list(metadata = list(unitList = unitlist))\n```\n:::\n\n\n### Edit factors\n\nFor attributes that are `enumeratedDomains`, a table is needed with three columns: `attributeName`, `code`, and `definition`.\n\n* **attributeName** should be the same as the `attributeName` within the attribute table and repeated for all codes belonging to a common attribute. \n* **code** should contain all unique values of the given `attributeName` that exist within the actual data.\n* **definition** should contain a plain text definition that describes each code.\n\nTo build factors by hand, you use the named character vectors and then convert them to a data.frame as shown in the example below. In this example, there are two enumerated domains in the attribute list - \"Location\" and \"Region\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nLocation <- c(CASC = 'Cascade Lake', CHIK = 'Chikumunik Lake', \n              HEAR = 'Heart Lake', NISH = 'Nishlik Lake' )\n\nRegion <- c(W_MTN = 'West region, locations West of Eagle Mountain', \n            E_MTN = 'East region, locations East of Eagle Mountain')\n```\n:::\n\n\nThe definitions are then written into a data.frame using the names of the named character vectors and their definitions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactors <- rbind(data.frame(attributeName = 'Location', \n                            code = names(Location), \n                            definition = unname(Location)),\n                  data.frame(attributeName = 'Region', code = names(Region), \n                             definition = unname(Region)))\n```\n:::\n\n\n### Finalize attributeList\n\nOnce you have built your attributes, factors, and custom units, you can add them to EML objects. Attributes and factors are combined to form an `attributeList` using the following command:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nattributeList <- EML::set_attributes(attributes = attributes,\n                                     factors = factors) \n```\n:::\n\n\nThis `attributeList` must then be [added to a `dataTable`](#edit-datatables).\n\n\n\n:::{.callout-note}\nRemember to use:\n`d1c_test <- dataone::D1Client(\"STAGING\", \"urn:node:mnTestARCTIC\")`\n`d1c_test@mn` \n:::\n\n## Set physical\n\nTo set the `physical` aspects of a data object, use the following commands to build a `physical` object from a data `PID` that exists in your package. **Remember to <a href = 'https://nceas.github.io/datateam-training/reference/set-dataone-nodes.html' target='_blank'>set the member node</a> to test.arcticdata.io!**\n\n:::{.callout-note}\nThe word ‘physical’ derives from database systems, which distinguish the ‘logical’ model (e.g., what attributes are in a table, etc) from the physical model (how the data are written to a physical hard disk (basically, the serialization). so,  we grouped metadata about the file (eg. dataformat, file size, file name) as written to disk in physical.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_pid <- selectMember(dp, name = \"sysmeta@fileName\", \n                         value = \"your_file_name.csv\")\n\nphysical <- arcticdatautils::pid_to_eml_physical(d1c@mn, data_pid)\n```\n:::\n\n\nThe `physical` must then be assigned to the data object.\n\nNote that the above workflow only works if your data object already exists on the member node.\n\n\n\n## Edit dataTables\n\nTo edit a `dataTable`, first [edit/create an `attributeList`](#edit-attributelists) and [set the physical](#set-physical). \nThen create a new `dataTable` using the `eml$dataTable()` helper function as below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndataTable <- eml$dataTable(entityName = \"A descriptive name for the data (does not need to be the same as the data file)\",\n                           entityDescription = \"A description of the data\",\n                           physical = physical,\n                           attributeList = attributeList)\n```\n:::\n\n\nThe `dataTable` must then be added to the EML. How exactly you do this will depend on whether there are `dataTable` elements in your EML, and how many there are. To replace whatever dataTable elements already exist, you could write:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$dataTable <- dataTable\n```\n:::\n\n\nIf there is only one `dataTable` in your dataset, the EML package will usually \"unpack\" these, so that it is not contained within a list of length 1 - this means that to add a second `dataTable`, you cannot use the syntax `doc$dataset$dataTable[[2]]`, since when unpacked this will contain the `entityDescription` as opposed to pointing to the second in a series of `dataTable` elements. Confusing - I know. Not to fear though - this syntax will get you on your way, should you be trying to add a second `dataTable`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$dataTable <- list(doc$dataset$dataTable, dataTable)\n```\n:::\n\n\nIf there is more than one `dataTable` in your dataset, you can return to the more straightforward construction of:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$dataTable[[i]] <- dataTable \n```\n:::\n\n\nWhere `i` is the index that you wish insert your `dataTable` into.\n\nTo add a list of `dataTables` to avoid the unpacking problem above you will need to create a list of `dataTables`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndts <- list() # create an empty list\nfor(i in seq_along(tables_you_need)){\n  # your code modifying/creating the dataTable here\n  dataTable <- eml$dataTable(entityName = dataTable$entityName,\n                             entityDescription = dataTable$entityDescription,\n                             physical = physical,\n                             attributeList = attributeList)\n  \n  dts[[i]] <- dataTable # add to the list\n}\n```\n:::\n\n\nAfter getting a list of `dataTables`, assign the resulting list to `dataTable` EML. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$dataTable <- dts\n```\n:::\n\n\n\nBy default, the online submission form adds all entities as `otherEntity`, even when most should probably be `dataTable`.  You can use `eml_otherEntity_to_dataTable` to easily move items in `otherEntity` over to `dataTable`. Most tabular data or data that contain variables should be listed as a `dataTable`. Data that do not contain variables (eg: plain text readme files, pdfs, jpegs) should be listed as `otherEntity`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\neml_otherEntity_to_dataTable(doc, \n                             1, # which otherEntities you want to convert, for multiple use - 1:5\n                             validate_eml = F) # set this to False if the physical or attributes are not added\n```\n:::\n\n\n## Edit otherEntities\n\n### Remove otherEntities\n\nTo remove an `otherEntity` use the following command. This may be useful if a data object is originally listed as an `otherEntity` and then transferred to a `dataTable`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$otherEntity[[i]] <- NULL\n```\n:::\n\n\n### Create otherEntities\n\nIf you need to create/update an `otherEntity`, make sure to <a href = 'https://nceas.github.io/datateam-training/reference/publish-an-object.html#publish-an-object' target='_blank'>publish</a> or <a href = 'https://nceas.github.io/datateam-training/reference/edit-otherentities.html#update-a-data-file' target='_blank'>update</a> your data object first (if it is not already on the DataONE MN). Then build your `otherEntity`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\notherEntity <- arcticdatautils::pid_to_eml_entity(mn, pkg$data[[i]])\n```\n:::\n\n\nAlternatively, you can build the `otherEntity` of a data object not in your package by simply inputting the data `PID`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\notherEntity <- arcticdatautils::pid_to_eml_entity(mn, \"your_data_pid\", entityType = \"otherEntity\", entityName = \"Entity Name\", entityDescription = \"Description about entity\")\n```\n:::\n\n\nThe `otherEntity` must then be set to the EML, like so: \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$otherEntity <- otherEntity\n```\n:::\n\n\nIf you have more than one `otherEntity` object in the EML already, you can add the new one like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$otherEntity[[i]] <- otherEntity\n```\n:::\n\n\nWhere `i` is set to the number of existing entities plus one. Remember the warning from the last section, however. If you only have one `otherEntity`, and you are trying to add another, you have to run:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$otherEntity <- list(otherEntity, doc$dataset$otherEntity)\n```\n:::\n\n\n\n## Semantic annotations\n\nFor a brief overview of what a semantic annotation is, and why we use them check out [this video.](https://drive.google.com/file/d/1Err-fL8O21kd1NzHJ9HJkK_B2fpt4sQW/view?usp=sharing)\n\nEven more information on how to add semantic annotations to EML 2.2.0 can be found\n <a href = 'https://eml.ecoinformatics.org/semantic-annotation-primer.html'>here</a>. Currently metacatUI does not support the editing of semantic annotations on the website so all changes will have to be done in R.\n \nThere are several elements in the EML 2.2.0 schema that can be annotated:\n\n* `dataset`\n* entity (eg: `otherEntity` or `dataTable`)\n* `attribute`\n\nOn the datateam, we will only be adding annotations to attributes for now.\n\n### How annotations are used\n\nThis is a  <a href = 'https://arcticdata.io/catalog/view/doi%3A10.18739%2FA2KW57J9Q'>dataset</a> that has semantic annotations included.\n\nOn the website you can see annotations in each of the attributes. \n\n![](../../images/annotations_web.png) \n \n![](../../images/annotations_web.png) \n\nYou can click on any one of them to search for more datasets with that same annotation. \n\n![](../../images/annotations_web_use.png) \n\n\n#### Attribute-level annotations\n\nTo add annotations to the `attributeList` you will need information about the `propertyURI` and `valueURI`\n\nAnnotations are essentially composed of a sentence, which contains a subject (the attribute), predicate (`propertyURI`),\nand object (`valueURI`). Because of the way our search interface is built, for now we will be using attribute annotations that have a `propertyURI` label of \"contains measurements of type\". \n\nHere is what an annotation for an attribute looks like in R. Note that both the `propertyURI` and `valueURI` have both a label, and the URI itself.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$dataTable[[i]]$attributeList$attribute[[i]]$annotation\n```\n:::\n\n```\n$id\n[1] \"ODBcOyaTsg\"\n\n$propertyURI\n$propertyURI$label\n[1] \"contains measurements of type\"\n\n$propertyURI$propertyURI\n[1] \"http://ecoinformatics.org/oboe/oboe.1.2/oboe-core.owl#containsMeasurementsOfType\"\n\n\n$valueURI\n$valueURI$label\n[1] \"Distributed Biological Observatory region identifier\"\n\n$valueURI$valueURI\n[1] \"http://purl.dataone.org/odo/ECSO_00002617\"\n```\n\n:::{.callout-note}\nSemantic attribute annotations can be applied to spatialRasters, spatialVectors and dataTables\n:::\n\n### How to add an annotation\n\n**1. Decide which variable to annotate**\n\nThe goal for the datateam is to start annotating every dataset that comes in. Please make sure to add semantic annotations to spatial and temporal features such as latitude, longitude, site name and date and aim to annotate as many attributes as possible.\n\n**2. Find an appropriate `valueURI`**\n\nThe next step is to find an appropriate value to fill in the blank of the sentence: \"this attribute contains measurements of _____.\"\n\nThere are several ontologies to search in. In order of most to least likely to be relevant to the Arctic Data Center they are:\n\n* [The Ecosystem Ontology (ECSO)](http://bioportal.bioontology.org/ontologies/ECSO/?p=classes&conceptid=http://purl.dataone.org/odo/ECSO_00002925)  \n    - this was developed at NCEAS, and has many terms that are relevant to ecosystem processes, especially those involving carbon and nutrient cycling\n* [The Environment Ontology (EnVO)](http://bioportal.bioontology.org/ontologies/ENVO/?p=classes&conceptid=root)\n    - this is an ontology for the concise, controlled description of environments\n* [National Center for Biotechnology Information (NCBI) Organismal Classification (NCBITAXON)](http://bioportal.bioontology.org/ontologies/NCBITAXON/?p=classes&conceptid=root)\n    - The NCBI Taxonomy Database is a curated classification and nomenclature for all of the organisms in the public sequence databases.\n* [Information Artifact Ontology (IAO)](http://bioportal.bioontology.org/ontologies/IAO/?p=summary)\n    - this ontology contains terms related to information entities (eg: journals, articles, datasets, identifiers)\n\nTo search, navigate through the \"classes\" until you find an appropriate term. When we are picking terms, it is important that we not just pick a similar term or a term that seems close -  we want a term that is totally \"right\". For example, if you have an attribute for carbon tetroxide flux and an ontology with a class hierarchy like this:\n\n-- carbon flux  \n  |---- carbon dioxide flux\n\nOur exact attribute, carbon tetroxide flux is not listed. In this case, we should pick \"carbon flux\" as it's completely correct and not \"carbon dioxide flux\" because it's more specific but not quite right.\n\n:::{.callout-note}\nFor general attributes (such as ones named depth or length), it is important to be as specific as possible about what is being measured. \n\ne.g. selecting the lake area annotation for the [area attribute](https://arcticdata.io/catalog/view/urn%3Auuid%3A64a3a75b-0630-44d2-a7e7-519029a48d9d#urn%3Auuid%3Ab8c29251-e628-405a-8e66-a5fa55703904) in this dataset\n:::\n\n**3. Build the annotation in R**\n\n#### Manually Annotating\n\n*this method is great for when you are inserting 1 annotation, fixing an existing annotation or programmatically updating annotations for multiple attributeLists*\n\nFirst you need to figure out the index of the attribute you want to annotate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\neml_get_simple(doc$dataset$dataTable[[3]]$attributeList, \"attributeName\")\n```\n:::\n\n\n```\n [1] \"prdM\"         \"t090C\"        \"t190C\"        \"c0mS/cm\"      \"c1mS/cm\"      \"sal00\"        \"sal11\"        \"sbeox0V\"      \"flECO-AFL\"\n[10] \"CStarTr0\"     \"cpar\"         \"v0\"           \"v4\"           \"v6\"           \"v7\"           \"svCM\"         \"altM\"         \"depSM\"    \n[19] \"scan\"         \"sbeox0ML/L\"   \"sbeox0dOV/dT\" \"flag\"    \n```\n\nNext, assign an `id` to the attribute. It should be unique within the document, and it's nice if it is human readable and related to the attribute it is describing. One format you could use is `entity_x_attribute_y` which should be unique in scope, and is nice and descriptive.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$dataTable[[3]]$attributeList$attribute[[6]]$id <- \"entity_ctd_attribute_salinity\"\n```\n:::\n\n\nNow, assign the `propertyURI` information. This will be the same for every annotation you build.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$dataTable[[3]]$attributeList$attribute[[6]]$annotation$propertyURI <- list(label = \"contains measurements of type\",\n                                                                                       propertyURI = \"http://ecoinformatics.org/oboe/oboe.1.2/oboe-core.owl#containsMeasurementsOfType\")\n```\n:::\n\n\nFinally, add the `valueURI` information from your search. \n\n![](../images/bioportal_term.png)\nYou should see an ID on the Bioportal page that looks like a URL - this is the `valueURI`. Use the value to populate the label element.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc$dataset$dataTable[[3]]$attributeList$attribute[[6]]$annotation$valueURI <- list(label = \"Water Salinity\",\n     valueURI = \"http://purl.dataone.org/odo/ECSO_00001164\")\n```\n:::\n\n\n#### Shiny Attributes\n\n*this method is great for when you are updating many attributes*\n\nOn the far right of the table of `shiny_attributes` there are 4 columns: `id`, `propertyURI`, `propertyLabel`, `valueURI`, `valueLabel` that can be filled out.\n\n### Annotating sensitive data\n\nSensitive datasets that might cover protected characteristics (human subjects data, endangered species locations, etc) should be annotated using the data sensitivity ontology: https://bioportal.bioontology.org/ontologies/SENSO/?p=classes&conceptid=root. \n\n#### Dataset Annotations\n\nAs a final step in the data processing pipeline, we will categorize the dataset. We are trying to categorize datasets so we can have a general idea of what kinds of data we have at the Arctic Data Center.\n\nDatasets will be categorized using the [Academic Ontology](https://bioportal.bioontology.org/ontologies/ADCAD/?p=classes&conceptid=root). These annotations will be seen at the top of the landing page, and can be thought of as \"themes\" for the dataset. In reality, they are dataset-level annotations.\n\nBe sure to ask your peers in the #datateam slack channel whether they agree with the themes you think best fit your dataset. Once there is consensus, use the following line of code: \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc <- datamgmt::eml_categorize_dataset(doc, c(\"list\", \"of\", \"themes\"))\n```\n:::\n\n\n\n\n## Exercise 3a {.exercise}\n\nThe metadata for the dataset created earlier in Exercise 2 was not very complete. Here we will add a attribute and physical to our entity (the csv file).\n\n* Make sure your package from [before](#exercise-2) is loaded into R.\n* Convert `otherEntity` into `dataTable`.\n* Replace the existing `dataTable` with a new `dataTable` object with an `attributelist` you write in R using the above commands.\n* We will continue using the objects created and updated in this exercise in 3b.\n\nBelow is some pseudo-code for how to accomplish the above steps. Fill in the dots according to the above sections to complete the exercise.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get the latest version of the resource map identifier from your dataset on the arctic data center\nresource_map_pid <- ...\ndp <- getDataPackage(d1c_test, identifier=resource_map_pid, lazyLoad=TRUE, quiet=FALSE)\n\n# get metadata pid\nmo <- selectMember(...)\n\n# read in EML\ndoc <- read_eml(getObject(...))\n\n# convert otherEntity to dataTable\ndoc <- eml_otherEntity_to_dataTable(...)\n\n# write an attribute list using shiny_attributes based on the data in your file\nex_data <- read.csv(...)\natts <- shiny_attributes(data = ex_data)\n\n# set the attributeList\ndoc$dataset$dataTable$attributeList <- set_attributes(...)\n```\n:::\n\n\n\n\n## Validate EML and update package\n\nTo make sure that your edited EML is valid against the EML schema, run `eml_validate()` on your EML. Fix any errors that you see.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neml_validate(doc)\n```\n:::\n\n\n\nYou should see something like if everything passes:\n>[1] TRUE\n>attr(,\"errors\")\n>character(0)\n\nThen save your EML to a path of your choice or a temp file. You will later pass this path as an argument to update the package.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neml_path <- \"path/to/save/eml.xml\"\nwrite_eml(doc, eml_path)\n```\n:::\n\n\n\n\n## Exercise 3b {.exercise}\n\n* Make sure you have everything from [before](#exercise-3a) in R.\n\nAfter adding more metadata, we want to publish the dataset onto `test.arcticdata.io`. Before we publish updates we need to do a couple checks before doing so.\n\n* Validate your metadata using `eml_validate`.\n* Use the [checklist](#final-checklist) to review your submission.\n* Make edits where necessary\n\nOnce `eml_validate` returns `TRUE` go ahead and run `write_eml`, `replaceMember`, and `uploadDataPackage`. There might be a small lag for your changes to appear on the website. This part of the workflow will look roughly like this:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# validate and write the EML\neml_validate(...)\nwrite_eml(...)\n\n# replace the old metadata file with the new one in the local package\ndp <- replaceMember(dp, ...)\n\n# upload the data package\npackageId <- uploadDataPackage(...)\n```\n:::\n",
    "supporting": [
      "04_editing_eml_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}