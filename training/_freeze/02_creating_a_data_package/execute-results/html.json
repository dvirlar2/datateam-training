{
  "hash": "b5c1ce0cdd4ff62d384d81ea009973ee",
  "result": {
    "markdown": "---\ntitle: \"Creating a data package\"\nfreeze: true\n---\n\n\nThis chapter will teach you how to create and submit a data package to a DataONE MN via R. But first, please read [this paper](data/eml-principles.pdf) on the value of structured metadata, namely the Ecological Metadata Language (EML).\n\n## What is in a package?\n\nA data package generally consists of at least 3 components. \n\n1. Metadata: One object is the metadata file itself. In case you are unfamiliar with metadata, metadata are information that describe data (e.g. who made the data, how were the data made, etc.). The metadata file will be in an XML format, and have the extension `.xml` (extensible markup language). We often refer to this file as the EML, which is the metadata standard that it uses. This is also what you see when you click on a page in the Arctic Data Center.\n\n2. Data: Other objects in a package are the data files themselves. Most commonly these are data tables (`.csv`), but they can also be audio files, NetCDF files, plain text files, PDF documents, image files, etc. \n\n3. Resource Map: The final object is the resource map. This object is a plain text file with the extension `.rdf` (<a href = 'https://www.w3.org/RDF/' target='_blank'>Resource Description Framework</a>) that defines the relationships between all of the other objects in the data package. It says things like \"this metadata file describes this data file,\" and is critical to making a data package render correctly on the website with the metadata file and all of the data files together in the correct place. Fortunately, we rarely, if ever, have to actually look at the contents of resource maps; they are generated for us using tools in R.\n\n![From the DataOne Community Meeting (Session 7)](images/data-submission-workflow2.png)\n\n## Packages on the Website\n\nAll of the package information is represented when you go to the landing page for a dataset. When you make changes through R those published changes will be reflected here. Although you can edit the metadata directly from the webpage but we recommend to use R in most cases.\n\n![](images/arctic_data_center_web.png)\n\n## About identifiers\n\nEach object (metadata files, data files, resource maps) on the ADC or the KNB (another repo) has a unique identifier, also sometimes called a \"PID\" (persistent identifier). When you look at the landing page for a dataset, for example <a href = 'https://arcticdata.io/catalog/#view/doi:10.18739/A2836Z' target='_blank'>here</a>, you can find the resource map identifier listed under the title in the gray bar after the words \"Files in this dataset Package:\" (`resource_map_doi:10.18739/A2836Z`), the metadata identifier in the \"General > Identifier\" section of the metadata record or after the title with blue font (`doi:10.18739/A2836Z`), and the data identifier by clicking the \"more info\" link next to the data object, and looking at the \"Online Distribution Info\" section (`arctic-data.9546.1`).\n\nNote, all datasets submitted are given a preliminary identifier (usually starting with `urn:uuid:`). When the dataset is finalized, a doi will be issued.\n\n\n![](images/PIDs.png)\n\n\nDifferent versions of a package are linked together by what we call the \"version chain\" or \"obsolescence chain\". Making an update to a data package, such as replacing a data file, changing a metadata record, etc, will result in a new identifier for the new version of the updated object. When making changes to a package, always use `datapack::uploadDataPackage()` for updating the entire package on the *latest versions* of all objects to ensure that the version chain is maintained.\n\n## Upload a package\n\nWe will be using R to connect to the <a href = 'https://arcticdata.io/catalog/#data' target='_blank'>NSF Arctic Data Center (ADC)</a> data repository to push and pull edits in actual datasets. To identify yourself as an admin you will need to pass a 'token' into R. Do this by signing in to the ADC with your ORCid and password, then hovering over your name in the top right corner and clicking on \"My profile\", then navigating to \"Settings\" and \"Authentication Token\", copying the \"Token for DataONE R\", and finally pasting and running it in your *R console*.\n\n:::{.callout-warning}\n**This token is your identity on these sites, please treat it as you would a password** (i.e. don't paste into scripts that will be shared). The easiest way to do this is to always run the token in the *console*. There's no need to keep it in your script since it's temporary anyway.\n:::\n\nYou will need to retrieve a new one after it either expires or you quit your R session.\n\nSometimes you'll see a placeholder in scripts to remind users to get their token, such as:\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(dataone_test_token = \"...\")\n```\n:::\n\n\n:::{.callout-note}\nSince we will be working on the test site and not the production site, please remember to get your token from test.arcticdata.io\n:::\n\nNext, please be sure these packages are loaded for the training (these should already exist if you are working on the server):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(devtools)\nlibrary(dataone)\nlibrary(datapack)\nlibrary(EML)\nlibrary(remotes)\nlibrary(XML)\nlibrary(uuid)\n```\n:::\n\n\nIf any package could not be loaded, use the following command (replacing package_name with the actual package name) to install the package, then load them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"package_name\")\n```\n:::\n\n\nNow you'll install the `arcticdatautils` and `datamgmt` packages with the code below. If prompted to update packages during the installation process, **skip the updates.** Now, run the following code to install and load the libraries.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nremotes::install_github(\"nceas/arcticdatautils\")\nlibrary(arcticdatautils)\nremotes::install_github(\"nceas/datamgmt\")\nlibrary(datamgmt)\n```\n:::\n\n\n:::{.callout-note}\nWhen you are usually working with data packages, you will only need the following: \n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dataone) \nlibrary(datapack)\nlibrary(EML)\nlibrary(arcticdatautils)\n```\n:::\n\n:::\n\nFor this training, we will be working exclusively on the Arctic test site, or \"node.\" In many of the functions you will use this will be the first argument. It is often referred to in documentation as `mn`, short for member node. More information on the other nodes can be found in the reference section under Set DataONE nodes [Set DataONE nodes](https://nceas.github.io/datateam-training/reference/set-dataone-nodes.html)\n\nFor example, if we are using the test site, set the node to the test Arctic node:\n\n\n::: {.cell}\n\n```{.r .exercise .cell-code}\nd1c_test <- dataone::D1Client(\"STAGING\", \"urn:node:mnTestARCTIC\")\n```\n:::\n\n\nOnce all set up you can first publish an object (data). If you are curious how everything magically works, here is a handy diagram:\n\n![From the DataOne Community Meeting (Session 7)](images/data-submission-workflow1.png)\n\n## datapack Background\n*adapted from the dataone and datapack vingettes*\n\n`datapack` is written differently than most R packages you may have encountered in the past. This is because it uses the [S4](https://adv-r.hadley.nz/s4.html) system instead.\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dataone)\nlibrary(datapack)\nlibrary(uuid)\n```\n:::\n\n**Data packages**\n\nData packages are a class that has slots for `relations` (provenance), `objects`(the metadata and data file(s)) and `systemMetadata`.\n\n### Navigating data packages\n\n**Nodes**\n\nUsing this example on arcticdata.io\n\n::: {.cell}\n\n```{.r .cell-code}\nd1c_test <- dataone::D1Client(\"STAGING\", \"urn:node:mnTestARCTIC\")\n```\n:::\n\nTo use the member node information, use the `mn` slot\n\n::: {.cell}\n\n```{.r .cell-code}\nd1c_test@mn\n```\n:::\n\n\n::: {.callout-note}\nTo access the various slots using objects created by datapack and dataone (e.g. `getSystemMetadata`) requires the `@` which is different from what you might have seen in the past. This is because these use the [S4](https://adv-r.hadley.nz/s4.html) system. \n:::\n\nGet an existing package from the Arctic Data Center. Make sure you know as you go through this training whether you are reading or writing to test or production. We don't want to upload any of your test datasets to production!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd1c <- dataone::D1Client(\"PROD\", \"urn:node:ARCTIC\")\ndp <- dataone::getDataPackage(d1c, \"resource_map_urn:uuid:1f9eee7e-2d03-43c4-ad7f-f300e013ab28\")\n```\n:::\n\n\n### Data Objects\n\nCheck out the `objects` slot \n\n::: {.cell}\n\n```{.r .cell-code}\ndp@objects\n```\n:::\n\nGet the number for data and metadata files associated with this data package:\n\n::: {.cell}\n\n```{.r .cell-code}\ngetSize(dp)\n```\n:::\n\nGet the file names and corresponding pids\n\n::: {.cell}\n\n```{.r .cell-code}\ngetValue(dp, name=\"sysmeta@fileName\")\n```\n:::\n\n\n**Get identifiers**\n\nYou can search by any of the `sysmeta` slots such as `fileName` and `formatId` and get the corresponding identifier(s):\n\n::: {.cell}\n\n```{.r .cell-code}\nmetadataId <- selectMember(dp, name=\"sysmeta@ADD THE NAME OF THE SLOT\", \n                           value=\"PATTERN TO SEARCH BY\")\n```\n:::\n\n\n**Example:** \n\n::: {.cell}\n\n```{.r .cell-code}\nselectMember(dp, name=\"sysmeta@formatId\", value=\"image/tiff\")\nselectMember(dp, name=\"sysmeta@fileName\", value=\"filename.csv\")\n```\n:::\n\n\n### Provenance\n\nView the provenance as a dataTable. We will get into detail in the Building provenance chapter.\n\n::: {.cell}\n\n```{.r .cell-code}\ndp@relations$relations\n```\n:::\n\n\n\n## Exercise 2a {.exercise}\n\nSelect a dataset from the [catalog](http://arcticdata.io/catalog) on the Arctic Data Center. Observe the number of data files in the dataset. Try to find identifiers for the metadata file and resource map on the landing page for the dataset based on the screenshot shown above.\n\n## Create a new data package\n*adapted from the dataone and datapack vingettes*\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dataone)\nlibrary(datapack)\nlibrary(uuid)\n```\n:::\n\nTo create a new data package, follow the code below. Remember, a data package is a class that has slots for `relations` (provenance), `objects`(the metadata and data file(s)) and `systemMetadata`.\n\n::: {.cell}\n\n```{.r .cell-code}\ndp <- new(\"DataPackage\")\n```\n:::\n\n### Upload new data files\n\n#### Create and add a metadata file\n\nIn this example we will use this previously written EML metadata. Here we are getting the file path from the dataone package and saving that as the object `emlFile`.\n\nThis is a bit of an unusual way to reference a local file path, but all this does is looks within the R package `dataone` and grabs the path to a metadata document stored within that package. If you print the value of `emlFile` you'll see it is just a file path, but it points to a special place on the server where that package is installed. Usually you will just reference EML paths that are stored within your user file system.\n\n::: {.cell}\n\n```{.r .cell-code}\nemlFile <- system.file(\"extdata/strix-pacific-northwest.xml\", \n                       package = \"dataone\")\n```\n:::\n\n\nCreate a new `DataObject` and add it to the package. In the case below, our new `DataObject` will be a metadata file.\n\n::: {.cell}\n\n```{.r .cell-code}\nmetadataObj <- new(\"DataObject\", \n                   format = \"https://eml.ecoinformatics.org/eml-2.2.0\", \n                   filename = emlFile)\n\ndp <- addMember(dp, metadataObj)\n```\n:::\n\nCheck the dp object to see if the `DataObject` was added correctly.\n\n::: {.cell}\n\n```{.r .cell-code}\ndp\n```\n:::\n\n#### Add some additional data files\n\n::: {.cell}\n\n```{.r .cell-code}\nsourceData <- system.file(\"extdata/OwlNightj.csv\", package = \"dataone\")\n\nsourceObj <- new(\"DataObject\", format = \"text/csv\", filename = sourceData)\n\ndp <- addMember(dp, sourceObj, metadataObj)\n```\n:::\n\n\n:::{.callout-note}\nIf you want to change the formatId please use `updateSystemMetadata` (more on this later in the book)\n:::\n\n### Upload the package\n\n::: {.cell}\n\n```{.r .cell-code}\nd1c <- dataone::D1Client(\"STAGING\", \"urn:node:mnTestARCTIC\")\n```\n:::\n\nMake sure to give access privileges to the ADC admins. Although you may be tempted to edit the format of the string in the `subject` argument, you must keep it exactly as is. Otherwise you'll run into error messages! \n\n::: {.cell}\n\n```{.r .cell-code}\nmyAccessRules <- data.frame(subject = \"CN=arctic-data-admins,DC=dataone,DC=org\", \n                            permission = \"changePermission\") \n```\n:::\n\nGet necessary token from [test.arcticdata.io](test.arcticdata.io) to upload the dataset prior uploading the datapackage: \n\n::: {.cell}\n\n```{.r .cell-code}\npackageId <- uploadDataPackage(d1c, dp, public = TRUE, \n                               accessRules = myAccessRules, quiet = FALSE)\n```\n:::\n\n\n\n:::{.callout-note}\n**If you want to preserve folder structures, you can use this method**\n\nIn this example, adding the csv files to a folder named data and scripts:\n\n::: {.cell}\n\n```{.r .cell-code}\noutputData <- system.file(\"extdata/Strix-occidentalis-obs.csv\", package=\"dataone\") \n\noutputObj <- new(\"DataObject\", format = \"text/csv\", filename = outputData,\n                 targetPath = \"data\")\n\ndp <- addMember(dp, outputObj, metadataObj)\n\nprogFile <- system.file(\"extdata/filterObs.R\", package = \"dataone\")\n\nprogObj <- new(\"DataObject\", format = \"application/R\", filename = progFile, \n               targetPath = \"scripts\", mediaType = \"text/x-rsrc\")\n\ndp <- addMember(dp, progObj, metadataObj)\n```\n:::\n:::\n\n\n\n\n## Exercise 2b {.exercise}\nThis exercise will take you through how to do the submission process through R instead of the webform (exercise 1).\n\n### Part 1 - Gather your data files\n\nFor our convenience, we will be grabbing the metadata and data files from the file we published earlier:\n\n* Locate the data package you published in [Exercise 1](#exercise-1) by navigating to the \"My Profile > My Data\" section on <a href = 'https://test.arcticdata.io' target='_blank'>test.arcticdata.io</a>.\n* Download the metadata and data files and transfer them to the Datateam server.\n\n### Part 2 - Working in R\n\nNow we want to publish the metadata and data files we downloaded again to `test.arcticdata.io`\n\n* Obtain a token and **please note** that for this exercise please make sure you grab the token from the <a href = 'https://test.arcticdata.io' target='_blank'> arcticdata test site</a>\n* Publish your metadata and data file to the site.\n\n\n::: {.cell}\n\n```{.r .exercise .cell-code}\n#set the node\nd1c_test <- dataone::D1Client(\"STAGING\", \"urn:node:mnTestARCTIC\")\ndp <- new(\"DataPackage\")\n\n#add your metadata\nmetadataObj <- new(...)\ndp <- addMember(...)\n\n#add your data files\nsourceObj <- new(...)\ndp <- addMember(...)\n\n#upload your package\nmyAccessRules <- data.frame(...) \npackageId <- uploadDataPackage(...)\n```\n:::\n\n\n* View your new data set by appending the metadata PID to the end of the URL test.arcticdata.io/#view/... \n* If you are successful it should look the same as the dataset you created in exercise 1\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}